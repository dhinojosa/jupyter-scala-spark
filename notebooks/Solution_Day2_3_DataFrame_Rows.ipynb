{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Add Rows \n",
    "\n",
    "**Step 1:** Read from the `../data/students.csv` file\n",
    "\n",
    "**Step 2:** Determine the count of data using `count()` on the `DataFrame`\n",
    "\n",
    "**Step 3:** Take the following students, create a `DataFrame` from it, and add it to the `DataFrame` you just loaded\n",
    "\n",
    "```\n",
    "265-0983,95,93,96,86\n",
    "613-3461,80,81,82,87\n",
    "173-6835,81,91,85,72\n",
    "146-4885,81,88,99,94\n",
    "202-5972,86,97,93,80\n",
    "619-2192,88,93,89,76\n",
    "064-0847,91,82,81,74\n",
    "684-5156,94,97,91,83\n",
    "```\n",
    "\n",
    "**Step 4:** Determine the count of the additional data\n",
    "\n",
    "**Step 5:** Write the data to a file called `../data/mergedstudents.csv`\n",
    "\n",
    "**Step 6:** Reread the file back in and determine if the `count` is still the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------------+----------+----------+\n",
      "|student_id|freshman_avg|sophomore_avg|junior_avg|senior_avg|\n",
      "+----------+------------+-------------+----------+----------+\n",
      "|  202-9509|          82|           90|        82|        82|\n",
      "|  645-9655|          91|           93|        99|        99|\n",
      "|  075-4491|          94|           84|        82|        78|\n",
      "|  191-7145|          95|           84|        90|        88|\n",
      "|  684-8946|          87|           90|        83|        86|\n",
      "|  243-7777|          94|           86|        83|        89|\n",
      "|  493-8040|          92|           95|        95|        71|\n",
      "|  314-1865|          89|           87|        88|        82|\n",
      "|  735-9127|          82|           98|        84|        99|\n",
      "|  279-9887|          98|           91|        79|        80|\n",
      "+----------+------------+-------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "readDF: org.apache.spark.sql.DataFrame = [student_id: string, freshman_avg: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val readDF = spark.read\n",
    "     .format(\"csv\")\n",
    "     .option(\"inferSchema\", \"true\")\n",
    "     .option(\"header\", \"true\")\n",
    "     .load(\"../data/students.csv\")\n",
    "readDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res13: Long = 42\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readDF.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StringType, IntegerType, StructType, StructField}\n",
       "import org.apache.spark.sql.Row\n",
       "rows: Seq[(String, Int, Int, Int, Int)] = List((265-0983,95,93,96,86), (613-3461,80,81,82,87), (173-6835,81,91,85,72), (146-4885,81,88,99,94), (202-5972,86,97,93,80), (619-2192,88,93,89,76), (064-0847,91,82,81,74), (684-5156,94,97,91,83))\n",
       "additionDF: org.apache.spark.sql.DataFrame = [student_id: string, freshman_avg: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StringType, IntegerType, StructType, StructField}\n",
    "import org.apache.spark.sql.Row\n",
    "val rows = Seq(\n",
    "(\"265-0983\",95,93,96,86),\n",
    "(\"613-3461\",80,81,82,87),\n",
    "(\"173-6835\",81,91,85,72),\n",
    "(\"146-4885\",81,88,99,94),\n",
    "(\"202-5972\",86,97,93,80),\n",
    "(\"619-2192\",88,93,89,76),\n",
    "(\"064-0847\",91,82,81,74),\n",
    "(\"684-5156\",94,97,91,83))\n",
    "\n",
    "val additionDF = rows.toDF(\"student_id\", \"freshman_avg\", \"sophomore_avg\", \"junior_avg\", \"senior_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res14: Long = 8\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additionDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mergedDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [student_id: string, freshman_avg: int ... 3 more fields]\n",
       "res15: Long = 50\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mergedDF = readDF.union(additionDF)\n",
    "mergedDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF.write\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"../data/mergedstudents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readMergedDF: org.apache.spark.sql.DataFrame = [student_id: string, freshman_avg: int ... 3 more fields]\n",
       "res18: Long = 50\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val readMergedDF = spark.read\n",
    "     .format(\"csv\")\n",
    "     .option(\"inferSchema\", \"true\")\n",
    "     .option(\"header\", \"true\")\n",
    "     .load(\"../data/mergedstudents.csv\")\n",
    "\n",
    "readMergedDF.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
