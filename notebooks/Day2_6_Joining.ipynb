{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining\n",
    "\n",
    "* It is often times required to join `DataTable` of to gain insight\n",
    "* Much like a database, Spark has varying joins\n",
    "* In Spark there are row joins called `union` and column joins like `left join`\n",
    "* There are varying joins: `inner`, `cross`, `outer`, `full`, `full_outer`, `left`, `left_outer`, `right`, `right_outer`, `left_semi`, `left_anti`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Rows\n",
    "\n",
    "Given two `DataSet`s or `DataFrame`s, we can join the rows by using `union`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://fb62c0c5dfbd:4042\n",
       "SparkContext available as 'sc' (version = 2.4.3, master = local[*], app id = local-1563898268663)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "countriesMedalCountDF: org.apache.spark.sql.DataFrame = [Country: string, Event: string ... 3 more fields]\n",
       "countriesMedalCountDF2: org.apache.spark.sql.DataFrame = [Country: string, Event: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val countriesMedalCountDF =\n",
    "      Seq((\"United States\", \"100m Freestyle\", 1, 0, 3),\n",
    "        (\"Spain\", \"100m Butterfly\", 2, 1, 1),\n",
    "        (\"Japan\", \"100m Butterfly\", 0, 3, 0),\n",
    "        (\"Spain\", \"100m Freestyle\", 0, 0, 3),\n",
    "        (\"Uruguay\", \"100m Breaststroke\", 0, 1, 0),\n",
    "        (\"United States\", \"100m Breaststroke\", 2, 2, 0))\n",
    "        .toDF(\"Country\", \"Event\", \"Gold\", \"Silver\", \"Bronze\")\n",
    "\n",
    "val countriesMedalCountDF2 =\n",
    "      Seq((\"United States\", \"100m Freestyle\", 1, 0, 3),\n",
    "        (\"Spain\", \"100m Backstroke\", 2, 1, 1),\n",
    "        (\"Spain\", \"200m Breaststroke\", 1, 0, 0),\n",
    "        (\"Spain\", \"500m Freestyle\", 3, 0, 0),\n",
    "        (\"Spain\", \"1000m Freestyle\", 2, 1, 0),\n",
    "        (\"United States\", \"100m Breaststroke\", 2, 2, 0))\n",
    "        .toDF(\"Country\", \"Event\", \"Gold\", \"Silver\", \"Bronze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A `union` joins all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+----+------+------+\n",
      "|      Country|            Event|Gold|Silver|Bronze|\n",
      "+-------------+-----------------+----+------+------+\n",
      "|United States|   100m Freestyle|   1|     0|     3|\n",
      "|        Spain|   100m Butterfly|   2|     1|     1|\n",
      "|        Japan|   100m Butterfly|   0|     3|     0|\n",
      "|        Spain|   100m Freestyle|   0|     0|     3|\n",
      "|      Uruguay|100m Breaststroke|   0|     1|     0|\n",
      "|United States|100m Breaststroke|   2|     2|     0|\n",
      "|United States|   100m Freestyle|   1|     0|     3|\n",
      "|        Spain|  100m Backstroke|   2|     1|     1|\n",
      "|        Spain|200m Breaststroke|   1|     0|     0|\n",
      "|        Spain|   500m Freestyle|   3|     0|     0|\n",
      "|        Spain|  1000m Freestyle|   2|     1|     0|\n",
      "|United States|100m Breaststroke|   2|     2|     0|\n",
      "+-------------+-----------------+----+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "unionDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Country: string, Event: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val unionDF = countriesMedalCountDF.union(countriesMedalCountDF2)\n",
    "unionDF.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can be selective which rows will be joined, by using a `where` or  `filter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+----+------+------+\n",
      "|      Country|            Event|Gold|Silver|Bronze|\n",
      "+-------------+-----------------+----+------+------+\n",
      "|United States|   100m Freestyle|   1|     0|     3|\n",
      "|        Spain|   100m Butterfly|   2|     1|     1|\n",
      "|        Japan|   100m Butterfly|   0|     3|     0|\n",
      "|        Spain|   100m Freestyle|   0|     0|     3|\n",
      "|      Uruguay|100m Breaststroke|   0|     1|     0|\n",
      "|United States|100m Breaststroke|   2|     2|     0|\n",
      "|        Spain|  100m Backstroke|   2|     1|     1|\n",
      "|        Spain|200m Breaststroke|   1|     0|     0|\n",
      "|        Spain|   500m Freestyle|   3|     0|     0|\n",
      "|        Spain|  1000m Freestyle|   2|     1|     0|\n",
      "+-------------+-----------------+----+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "unionDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Country: string, Event: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val unionDF = countriesMedalCountDF.union(countriesMedalCountDF2.where(\"country = 'Spain'\"))\n",
    "unionDF.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `union` just add just one `Row` to the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+----+------+------+\n",
      "|      Country|            Event|Gold|Silver|Bronze|\n",
      "+-------------+-----------------+----+------+------+\n",
      "|United States|   100m Freestyle|   1|     0|     3|\n",
      "|        Spain|   100m Butterfly|   2|     1|     1|\n",
      "|        Japan|   100m Butterfly|   0|     3|     0|\n",
      "|        Spain|   100m Freestyle|   0|     0|     3|\n",
      "|      Uruguay|100m Breaststroke|   0|     1|     0|\n",
      "|United States|100m Breaststroke|   2|     2|     0|\n",
      "|        Italy|   500m Freestyle|   0|     1|     0|\n",
      "+-------------+-----------------+----+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "addedItalyDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Country: string, Event: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val addedItalyDF = countriesMedalCountDF.union(Seq((\"Italy\", \"500m Freestyle\", 0, 1, 0)).toDF(\"Country\", \"Event\", \"Gold\", \"Silver\", \"Bronze\"))\n",
    "addedItalyDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Columns\n",
    "\n",
    "How we join columns, we have a selection of the joins to choose from each with its own side effect, and we will see each of these in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.DataFrame\n",
       "cities: org.apache.spark.sql.DataFrame = [id: int, city: string ... 1 more field]\n",
       "teams: org.apache.spark.sql.DataFrame = [id: int, city: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "val cities: DataFrame = Seq(\n",
    "    (1, \"San Francisco\", \"CA\"),\n",
    "    (2, \"Dallas\", \"TX\"),\n",
    "    (3, \"Pittsburgh\", \"PA\"),\n",
    "    (4, \"Buffalo\", \"NY\"),\n",
    "    (5, \"Oklahoma City\", \"OK\"),\n",
    "    (6, \"New York\", \"NY\"),\n",
    "    (7, \"Los Angeles\", \"CA\"),\n",
    "    (8, \"Omaha\", \"NE\")).toDF(\"id\", \"city\", \"state\")\n",
    "\n",
    "val teams: DataFrame = Seq(\n",
    "    (1, \"Los Angeles\", \"Rams\", \"Football\"),\n",
    "    (2, \"Los Angeles\", \"Dodgers\", \"Baseball\"),\n",
    "    (3, \"New York\", \"Giants\", \"Football\"),\n",
    "    (4, \"San Francisco\", \"Giants\", \"Baseball\"),\n",
    "    (5, \"Buffalo\", \"Bills\", \"Football\"),\n",
    "    (6, \"Pittsburg\", \"Pirates\", \"Baseball\"),\n",
    "    (7, \"San Francisco\", \"49ers\", \"Football\"),\n",
    "    (8, \"San Diego\", \"Padres\", \"Baseball\"),\n",
    "    (9, \"Seattle\", \"Mariners\", \"Baseball\"),\n",
    "    (10, \"Seattle\", \"Sounders\", \"Soccer\"),\n",
    "    (11, \"Portland\", \"Timbers\", \"Soccer\"),\n",
    "    (12, \"Pittsburgh\", \"Steelers\", \"Football\")).toDF(\"id\", \"city\", \"team\", \"sport_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Joins\n",
    "\n",
    "* `join` performs an inner join with a given expression\n",
    "* Rows from either table that are unmatched in the other table are not returned\n",
    "* Notice that there is no `Omaha`, `Oklahoma City` or `Dallas` since there isn't a corresponding right value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----+---+-------------+--------+----------+\n",
      "| id|         city|state| id|         city|    team|sport_type|\n",
      "+---+-------------+-----+---+-------------+--------+----------+\n",
      "|  7|  Los Angeles|   CA|  1|  Los Angeles|    Rams|  Football|\n",
      "|  7|  Los Angeles|   CA|  2|  Los Angeles| Dodgers|  Baseball|\n",
      "|  6|     New York|   NY|  3|     New York|  Giants|  Football|\n",
      "|  1|San Francisco|   CA|  4|San Francisco|  Giants|  Baseball|\n",
      "|  4|      Buffalo|   NY|  5|      Buffalo|   Bills|  Football|\n",
      "|  1|San Francisco|   CA|  7|San Francisco|   49ers|  Football|\n",
      "|  3|   Pittsburgh|   PA| 12|   Pittsburgh|Steelers|  Football|\n",
      "+---+-------------+-----+---+-------------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "innerjoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val innerjoin = cities\n",
    "      .join(teams, cities.col(\"city\") === teams.col(\"city\"))\n",
    "innerjoin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Inner Joins\n",
    "\n",
    "* We can explicitly set an `inner` join by declaring it as a joinType\n",
    "* Below we set `joinType`, you can leave the assignment `joinType` if you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----+---+-------------+--------+----------+\n",
      "| id|         city|state| id|         city|    team|sport_type|\n",
      "+---+-------------+-----+---+-------------+--------+----------+\n",
      "|  7|  Los Angeles|   CA|  1|  Los Angeles|    Rams|  Football|\n",
      "|  7|  Los Angeles|   CA|  2|  Los Angeles| Dodgers|  Baseball|\n",
      "|  6|     New York|   NY|  3|     New York|  Giants|  Football|\n",
      "|  1|San Francisco|   CA|  4|San Francisco|  Giants|  Baseball|\n",
      "|  4|      Buffalo|   NY|  5|      Buffalo|   Bills|  Football|\n",
      "|  1|San Francisco|   CA|  7|San Francisco|   49ers|  Football|\n",
      "|  3|   Pittsburgh|   PA| 12|   Pittsburgh|Steelers|  Football|\n",
      "+---+-------------+-----+---+-------------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "innerjoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val innerjoin = cities\n",
    "      .join(teams, cities.col(\"city\") === teams.col(\"city\"), joinType=\"inner\")\n",
    "innerjoin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Joins\n",
    "\n",
    "* `joinType` of `left` or `left_outer` performs an left join with a given expression\n",
    "* Returns all records from the left `DataFrame`, and the matched records from the right `DataFrame`\n",
    "* The result is `null` from the right side, if there is no match\n",
    "* Notice that there are `null`s for `Omaha`, `Oklahoma City` or `Dallas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----+----+-------------+--------+----------+\n",
      "| id|         city|state|  id|         city|    team|sport_type|\n",
      "+---+-------------+-----+----+-------------+--------+----------+\n",
      "|  1|San Francisco|   CA|   7|San Francisco|   49ers|  Football|\n",
      "|  1|San Francisco|   CA|   4|San Francisco|  Giants|  Baseball|\n",
      "|  2|       Dallas|   TX|null|         null|    null|      null|\n",
      "|  3|   Pittsburgh|   PA|  12|   Pittsburgh|Steelers|  Football|\n",
      "|  4|      Buffalo|   NY|   5|      Buffalo|   Bills|  Football|\n",
      "|  5|Oklahoma City|   OK|null|         null|    null|      null|\n",
      "|  6|     New York|   NY|   3|     New York|  Giants|  Football|\n",
      "|  7|  Los Angeles|   CA|   2|  Los Angeles| Dodgers|  Baseball|\n",
      "|  7|  Los Angeles|   CA|   1|  Los Angeles|    Rams|  Football|\n",
      "|  8|        Omaha|   NE|null|         null|    null|      null|\n",
      "+---+-------------+-----+----+-------------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "leftjoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val leftjoin = cities\n",
    "      .join(teams, cities.col(\"city\") === teams.col(\"city\"), joinType=\"left\")\n",
    "leftjoin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----+----+-------------+--------+----------+\n",
      "| id|         city|state|  id|         city|    team|sport_type|\n",
      "+---+-------------+-----+----+-------------+--------+----------+\n",
      "|  1|San Francisco|   CA|   7|San Francisco|   49ers|  Football|\n",
      "|  1|San Francisco|   CA|   4|San Francisco|  Giants|  Baseball|\n",
      "|  2|       Dallas|   TX|null|         null|    null|      null|\n",
      "|  3|   Pittsburgh|   PA|  12|   Pittsburgh|Steelers|  Football|\n",
      "|  4|      Buffalo|   NY|   5|      Buffalo|   Bills|  Football|\n",
      "|  5|Oklahoma City|   OK|null|         null|    null|      null|\n",
      "|  6|     New York|   NY|   3|     New York|  Giants|  Football|\n",
      "|  7|  Los Angeles|   CA|   2|  Los Angeles| Dodgers|  Baseball|\n",
      "|  7|  Los Angeles|   CA|   1|  Los Angeles|    Rams|  Football|\n",
      "|  8|        Omaha|   NE|null|         null|    null|      null|\n",
      "+---+-------------+-----+----+-------------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "outerleftjoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val outerleftjoin = cities\n",
    "      .join(teams, cities.col(\"city\") === teams.col(\"city\"), joinType=\"left_outer\")\n",
    "outerleftjoin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Joins\n",
    "\n",
    "* `right` or `right_outer` performs an right join with a given expression\n",
    "* Returns all records from the right `DataFrame`, and the matched records from the left `DataFame`. \n",
    "* The result is `null` from the left side, when there is no match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----+---+-------------+--------+----------+\n",
      "|  id|         city|state| id|         city|    team|sport_type|\n",
      "+----+-------------+-----+---+-------------+--------+----------+\n",
      "|   7|  Los Angeles|   CA|  1|  Los Angeles|    Rams|  Football|\n",
      "|   7|  Los Angeles|   CA|  2|  Los Angeles| Dodgers|  Baseball|\n",
      "|   6|     New York|   NY|  3|     New York|  Giants|  Football|\n",
      "|   1|San Francisco|   CA|  4|San Francisco|  Giants|  Baseball|\n",
      "|   4|      Buffalo|   NY|  5|      Buffalo|   Bills|  Football|\n",
      "|null|         null| null|  6|    Pittsburg| Pirates|  Baseball|\n",
      "|   1|San Francisco|   CA|  7|San Francisco|   49ers|  Football|\n",
      "|null|         null| null|  8|    San Diego|  Padres|  Baseball|\n",
      "|null|         null| null|  9|      Seattle|Mariners|  Baseball|\n",
      "|null|         null| null| 10|      Seattle|Sounders|    Soccer|\n",
      "|null|         null| null| 11|     Portland| Timbers|    Soccer|\n",
      "|   3|   Pittsburgh|   PA| 12|   Pittsburgh|Steelers|  Football|\n",
      "+----+-------------+-----+---+-------------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rightjoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rightjoin = cities\n",
    "      .join(teams, cities.col(\"city\") === teams.col(\"city\"), joinType=\"right\")\n",
    "rightjoin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----+---+-------------+--------+----------+\n",
      "|  id|         city|state| id|         city|    team|sport_type|\n",
      "+----+-------------+-----+---+-------------+--------+----------+\n",
      "|   7|  Los Angeles|   CA|  1|  Los Angeles|    Rams|  Football|\n",
      "|   7|  Los Angeles|   CA|  2|  Los Angeles| Dodgers|  Baseball|\n",
      "|   6|     New York|   NY|  3|     New York|  Giants|  Football|\n",
      "|   1|San Francisco|   CA|  4|San Francisco|  Giants|  Baseball|\n",
      "|   4|      Buffalo|   NY|  5|      Buffalo|   Bills|  Football|\n",
      "|null|         null| null|  6|    Pittsburg| Pirates|  Baseball|\n",
      "|   1|San Francisco|   CA|  7|San Francisco|   49ers|  Football|\n",
      "|null|         null| null|  8|    San Diego|  Padres|  Baseball|\n",
      "|null|         null| null|  9|      Seattle|Mariners|  Baseball|\n",
      "|null|         null| null| 10|      Seattle|Sounders|    Soccer|\n",
      "|null|         null| null| 11|     Portland| Timbers|    Soccer|\n",
      "|   3|   Pittsburgh|   PA| 12|   Pittsburgh|Steelers|  Football|\n",
      "+----+-------------+-----+---+-------------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rightjoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rightjoin = cities\n",
    "      .join(teams, cities.col(\"city\") === teams.col(\"city\"), joinType=\"right_outer\")\n",
    "rightjoin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Joins\n",
    "* `join` with a quality of `outer` performs an `outer` join with a given expression\n",
    "* Unmatched rows in one or both `DataFrame`s can be returned\n",
    "* `outer_join` and `full_outer_join` return the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----+----+-------------+--------+----------+\n",
      "|  id|         city|state|  id|         city|    team|sport_type|\n",
      "+----+-------------+-----+----+-------------+--------+----------+\n",
      "|null|         null| null|   6|    Pittsburg| Pirates|  Baseball|\n",
      "|   8|        Omaha|   NE|null|         null|    null|      null|\n",
      "|   2|       Dallas|   TX|null|         null|    null|      null|\n",
      "|   7|  Los Angeles|   CA|   1|  Los Angeles|    Rams|  Football|\n",
      "|   7|  Los Angeles|   CA|   2|  Los Angeles| Dodgers|  Baseball|\n",
      "|   5|Oklahoma City|   OK|null|         null|    null|      null|\n",
      "|null|         null| null|   8|    San Diego|  Padres|  Baseball|\n",
      "|   1|San Francisco|   CA|   4|San Francisco|  Giants|  Baseball|\n",
      "|   1|San Francisco|   CA|   7|San Francisco|   49ers|  Football|\n",
      "|null|         null| null|  11|     Portland| Timbers|    Soccer|\n",
      "|   3|   Pittsburgh|   PA|  12|   Pittsburgh|Steelers|  Football|\n",
      "|null|         null| null|   9|      Seattle|Mariners|  Baseball|\n",
      "|null|         null| null|  10|      Seattle|Sounders|    Soccer|\n",
      "|   4|      Buffalo|   NY|   5|      Buffalo|   Bills|  Football|\n",
      "|   6|     New York|   NY|   3|     New York|  Giants|  Football|\n",
      "+----+-------------+-----+----+-------------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "outerjoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val outerjoin = cities.join(teams, cities.col(\"city\") === teams.col(\"city\"), joinType = \"outer\")\n",
    "outerjoin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+-----+----+-------------+--------+----------+\n",
      "|  id|         city|state|  id|         city|    team|sport_type|\n",
      "+----+-------------+-----+----+-------------+--------+----------+\n",
      "|null|         null| null|   6|    Pittsburg| Pirates|  Baseball|\n",
      "|   8|        Omaha|   NE|null|         null|    null|      null|\n",
      "|   2|       Dallas|   TX|null|         null|    null|      null|\n",
      "|   7|  Los Angeles|   CA|   1|  Los Angeles|    Rams|  Football|\n",
      "|   7|  Los Angeles|   CA|   2|  Los Angeles| Dodgers|  Baseball|\n",
      "|   5|Oklahoma City|   OK|null|         null|    null|      null|\n",
      "|null|         null| null|   8|    San Diego|  Padres|  Baseball|\n",
      "|   1|San Francisco|   CA|   4|San Francisco|  Giants|  Baseball|\n",
      "|   1|San Francisco|   CA|   7|San Francisco|   49ers|  Football|\n",
      "|null|         null| null|  11|     Portland| Timbers|    Soccer|\n",
      "|   3|   Pittsburgh|   PA|  12|   Pittsburgh|Steelers|  Football|\n",
      "|null|         null| null|   9|      Seattle|Mariners|  Baseball|\n",
      "|null|         null| null|  10|      Seattle|Sounders|    Soccer|\n",
      "|   4|      Buffalo|   NY|   5|      Buffalo|   Bills|  Football|\n",
      "|   6|     New York|   NY|   3|     New York|  Giants|  Football|\n",
      "+----+-------------+-----+----+-------------+--------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fullouterjoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fullouterjoin = cities.join(teams, cities.col(\"city\") === teams.col(\"city\"), joinType = \"full_outer\")\n",
    "fullouterjoin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Join\n",
    "\n",
    "* A `crossJoin` join forms a cartesian join where every element on the left is associated on the right\n",
    "* Analogous to a nested for-loop in programming\n",
    "* Perhaps we want to build a baseball schedule for the next season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+----------+---+-------------+--------+----------+\n",
      "| id|         city|   team|sport_type| id|         city|    team|sport_type|\n",
      "+---+-------------+-------+----------+---+-------------+--------+----------+\n",
      "|  2|  Los Angeles|Dodgers|  Baseball|  2|  Los Angeles| Dodgers|  Baseball|\n",
      "|  2|  Los Angeles|Dodgers|  Baseball|  4|San Francisco|  Giants|  Baseball|\n",
      "|  2|  Los Angeles|Dodgers|  Baseball|  6|    Pittsburg| Pirates|  Baseball|\n",
      "|  2|  Los Angeles|Dodgers|  Baseball|  8|    San Diego|  Padres|  Baseball|\n",
      "|  2|  Los Angeles|Dodgers|  Baseball|  9|      Seattle|Mariners|  Baseball|\n",
      "|  4|San Francisco| Giants|  Baseball|  2|  Los Angeles| Dodgers|  Baseball|\n",
      "|  4|San Francisco| Giants|  Baseball|  4|San Francisco|  Giants|  Baseball|\n",
      "|  4|San Francisco| Giants|  Baseball|  6|    Pittsburg| Pirates|  Baseball|\n",
      "|  4|San Francisco| Giants|  Baseball|  8|    San Diego|  Padres|  Baseball|\n",
      "|  4|San Francisco| Giants|  Baseball|  9|      Seattle|Mariners|  Baseball|\n",
      "|  6|    Pittsburg|Pirates|  Baseball|  2|  Los Angeles| Dodgers|  Baseball|\n",
      "|  6|    Pittsburg|Pirates|  Baseball|  4|San Francisco|  Giants|  Baseball|\n",
      "|  6|    Pittsburg|Pirates|  Baseball|  6|    Pittsburg| Pirates|  Baseball|\n",
      "|  6|    Pittsburg|Pirates|  Baseball|  8|    San Diego|  Padres|  Baseball|\n",
      "|  6|    Pittsburg|Pirates|  Baseball|  9|      Seattle|Mariners|  Baseball|\n",
      "|  8|    San Diego| Padres|  Baseball|  2|  Los Angeles| Dodgers|  Baseball|\n",
      "|  8|    San Diego| Padres|  Baseball|  4|San Francisco|  Giants|  Baseball|\n",
      "|  8|    San Diego| Padres|  Baseball|  6|    Pittsburg| Pirates|  Baseball|\n",
      "|  8|    San Diego| Padres|  Baseball|  8|    San Diego|  Padres|  Baseball|\n",
      "|  8|    San Diego| Padres|  Baseball|  9|      Seattle|Mariners|  Baseball|\n",
      "+---+-------------+-------+----------+---+-------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "baseballTeams: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, city: string ... 2 more fields]\n",
       "crossJoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 6 more fields]\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val baseballTeams = teams.where(\"sport_type = 'Baseball'\")\n",
    "val crossJoin = baseballTeams.crossJoin(baseballTeams)\n",
    "crossJoin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Those column names are a bit confusing and repetitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+---------+---------------+-------+-------------+---------+---------------+\n",
      "|home_id|    home_city|home_team|home_sport_type|away_id|    away_city|away_team|away_sport_type|\n",
      "+-------+-------------+---------+---------------+-------+-------------+---------+---------------+\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "+-------+-------------+---------+---------------+-------+-------------+---------+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "baseballTeams: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, city: string ... 2 more fields]\n",
       "crossJoin: org.apache.spark.sql.DataFrame = [id: int, city: string ... 6 more fields]\n",
       "newColumnNames: Seq[String] = List(home_id, home_city, home_team, home_sport_type, away_id, away_city, away_team, away_sport_type)\n",
       "crossJoinWithNewColumnNames: org.apache.spark.sql.DataFrame = [home_id: int, home_city: string ... 6 more fields]\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newColumnNames = Seq(\"home_id\", \"home_city\", \"home_team\", \"home_sport_type\", \n",
    "                         \"away_id\", \"away_city\", \"away_team\", \"away_sport_type\")\n",
    "val crossJoinWithNewColumnNames = crossJoin.toDF(newColumnNames:_*)\n",
    "crossJoinWithNewColumnNames.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all the rows where there is the same team for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+---------+---------------+-------+-------------+---------+---------------+\n",
      "|home_id|    home_city|home_team|home_sport_type|away_id|    away_city|away_team|away_sport_type|\n",
      "+-------+-------------+---------+---------------+-------+-------------+---------+---------------+\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "|      2|  Los Angeles|  Dodgers|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "|      4|San Francisco|   Giants|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "|      6|    Pittsburg|  Pirates|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      8|    San Diego|   Padres|       Baseball|      9|      Seattle| Mariners|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      2|  Los Angeles|  Dodgers|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      4|San Francisco|   Giants|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      6|    Pittsburg|  Pirates|       Baseball|\n",
      "|      9|      Seattle| Mariners|       Baseball|      8|    San Diego|   Padres|       Baseball|\n",
      "+-------+-------------+---------+---------------+-------+-------------+---------+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "removedSameTeam: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [home_id: int, home_city: string ... 6 more fields]\n"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val removedSameTeam = crossJoinWithNewColumnNames.where(\"away_team != home_team\")\n",
    "removedSameTeam.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing some Useless Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------------+---------+\n",
      "|    home_city|home_team|    away_city|away_team|\n",
      "+-------------+---------+-------------+---------+\n",
      "|  Los Angeles|  Dodgers|San Francisco|   Giants|\n",
      "|  Los Angeles|  Dodgers|    Pittsburg|  Pirates|\n",
      "|  Los Angeles|  Dodgers|    San Diego|   Padres|\n",
      "|  Los Angeles|  Dodgers|      Seattle| Mariners|\n",
      "|San Francisco|   Giants|  Los Angeles|  Dodgers|\n",
      "|San Francisco|   Giants|    Pittsburg|  Pirates|\n",
      "|San Francisco|   Giants|    San Diego|   Padres|\n",
      "|San Francisco|   Giants|      Seattle| Mariners|\n",
      "|    Pittsburg|  Pirates|  Los Angeles|  Dodgers|\n",
      "|    Pittsburg|  Pirates|San Francisco|   Giants|\n",
      "|    Pittsburg|  Pirates|    San Diego|   Padres|\n",
      "|    Pittsburg|  Pirates|      Seattle| Mariners|\n",
      "|    San Diego|   Padres|  Los Angeles|  Dodgers|\n",
      "|    San Diego|   Padres|San Francisco|   Giants|\n",
      "|    San Diego|   Padres|    Pittsburg|  Pirates|\n",
      "|    San Diego|   Padres|      Seattle| Mariners|\n",
      "|      Seattle| Mariners|  Los Angeles|  Dodgers|\n",
      "|      Seattle| Mariners|San Francisco|   Giants|\n",
      "|      Seattle| Mariners|    Pittsburg|  Pirates|\n",
      "|      Seattle| Mariners|    San Diego|   Padres|\n",
      "+-------------+---------+-------------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cleanTeams: org.apache.spark.sql.DataFrame = [home_city: string, home_team: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cleanTeams = removedSameTeam.drop(\"home_id\", \"home_sport_type\", \"away_id\", \"away_sport_type\")\n",
    "cleanTeams.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Joining the wine list "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
