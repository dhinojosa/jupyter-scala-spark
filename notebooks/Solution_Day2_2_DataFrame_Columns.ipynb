{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns\n",
    "\n",
    "* Columns simply are the columns of the `DataFrame`\n",
    "* Columns are selectable and are easy to configuture\n",
    "* Columns can be added and removed\n",
    "* Columns represent a simple type like an integer or string, a complex type like an array or map, or a null value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing in the books dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bookID: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- # num_pages: string (nullable = true)\n",
      " |-- ratings_count: integer (nullable = true)\n",
      " |-- text_reviews_count: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "booksDF: org.apache.spark.sql.DataFrame = [bookID: int, title: string ... 8 more fields]\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val booksDF = spark.read.format(\"csv\")\n",
    "                     .option(\"inferSchema\", \"true\")\n",
    "                     .option(\"header\", \"true\")\n",
    "                     .load(\"../data/books.csv\")\n",
    "\n",
    "booksDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing `Column`\n",
    "\n",
    "* Columns are represented by any of the following declarations\n",
    "* The last two are possible by using `implicits` in Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, column}\n",
       "res27: Symbol = 'someColumnName\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, column}\n",
    "\n",
    "col(\"someColumnName\")\n",
    "column(\"someColumnName\")\n",
    "$\"someColumnName\"\n",
    "'someColumnName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting column representation from `DataFrame`\n",
    "\n",
    "* We can also use `col` from the `DataFrame` to select one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res28: org.apache.spark.sql.Column = average_rating\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booksDF.col(\"average_rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns to be displayed with `select`\n",
    "\n",
    "* Select one or more columns using `select`\n",
    "* You can use whatever column form you please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+\n",
      "|ratings_count|               title|             authors|\n",
      "+-------------+--------------------+--------------------+\n",
      "|      1944099|Harry Potter and ...|J.K. Rowling-Mary...|\n",
      "|      1996446|Harry Potter and ...|J.K. Rowling-Mary...|\n",
      "|      5629932|Harry Potter and ...|J.K. Rowling-Mary...|\n",
      "|         6267|Harry Potter and ...|        J.K. Rowling|\n",
      "|      2149872|Harry Potter and ...|J.K. Rowling-Mary...|\n",
      "|        38872|Harry Potter Boxe...|J.K. Rowling-Mary...|\n",
      "|           18|Unauthorized Harr...|W. Frederick Zimm...|\n",
      "|        27410|Harry Potter Coll...|        J.K. Rowling|\n",
      "|         3602|The Ultimate Hitc...|       Douglas Adams|\n",
      "|       240189|The Ultimate Hitc...|       Douglas Adams|\n",
      "|         4416|The Hitchhiker's ...|       Douglas Adams|\n",
      "|         1222|The Hitchhiker's ...|Douglas Adams-Ste...|\n",
      "|         2801|The Ultimate Hitc...|       Douglas Adams|\n",
      "|       228522|A Short History o...|Bill Bryson-Willi...|\n",
      "|         6993|Bill Bryson's Afr...|         Bill Bryson|\n",
      "|         2020|Bryson's Dictiona...|         Bill Bryson|\n",
      "|        68213|In a Sunburned Co...|         Bill Bryson|\n",
      "|        47490|I'm a Stranger He...|         Bill Bryson|\n",
      "|        43779|The Lost Continen...|         Bill Bryson|\n",
      "|        46397|Neither Here nor ...|         Bill Bryson|\n",
      "+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subset: org.apache.spark.sql.DataFrame = [ratings_count: int, title: string ... 1 more field]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val subset = booksDF.select($\"ratings_count\", col(\"title\"), 'authors)\n",
    "subset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|num_ratings|               title|             authors|\n",
      "+-----------+--------------------+--------------------+\n",
      "|    1944099|Harry Potter and ...|J.K. Rowling-Mary...|\n",
      "|    1996446|Harry Potter and ...|J.K. Rowling-Mary...|\n",
      "|    5629932|Harry Potter and ...|J.K. Rowling-Mary...|\n",
      "|       6267|Harry Potter and ...|        J.K. Rowling|\n",
      "|    2149872|Harry Potter and ...|J.K. Rowling-Mary...|\n",
      "|      38872|Harry Potter Boxe...|J.K. Rowling-Mary...|\n",
      "|         18|Unauthorized Harr...|W. Frederick Zimm...|\n",
      "|      27410|Harry Potter Coll...|        J.K. Rowling|\n",
      "|       3602|The Ultimate Hitc...|       Douglas Adams|\n",
      "|     240189|The Ultimate Hitc...|       Douglas Adams|\n",
      "|       4416|The Hitchhiker's ...|       Douglas Adams|\n",
      "|       1222|The Hitchhiker's ...|Douglas Adams-Ste...|\n",
      "|       2801|The Ultimate Hitc...|       Douglas Adams|\n",
      "|     228522|A Short History o...|Bill Bryson-Willi...|\n",
      "|       6993|Bill Bryson's Afr...|         Bill Bryson|\n",
      "|       2020|Bryson's Dictiona...|         Bill Bryson|\n",
      "|      68213|In a Sunburned Co...|         Bill Bryson|\n",
      "|      47490|I'm a Stranger He...|         Bill Bryson|\n",
      "|      43779|The Lost Continen...|         Bill Bryson|\n",
      "|      46397|Neither Here nor ...|         Bill Bryson|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subset: org.apache.spark.sql.DataFrame = [num_ratings: int, title: string ... 1 more field]\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val subset = booksDF.select($\"ratings_count\".as(\"num_ratings\"), col(\"title\"), 'authors)\n",
    "subset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- num_ratings: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmatically accessing columns\n",
    "\n",
    "* We can access the columns programmatically using `columns` from the `DataFrame`\n",
    "* This returns an `Array[String]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res20: Array[String] = Array(bookID, title, authors, average_rating, isbn, isbn13, language_code, # num_pages, ratings_count, text_reviews_count)\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booksDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming a column\n",
    "\n",
    "* We can rename a column with `withColumnRenamed` with the first parameter being the old column, and the second being the new one.\n",
    "* This returns a new `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bookID: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- # num_pages: string (nullable = true)\n",
      " |-- ratings_count: integer (nullable = true)\n",
      " |-- reviews_count: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "booksRenamedDF: org.apache.spark.sql.DataFrame = [bookID: int, title: string ... 8 more fields]\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val booksRenamedDF = booksDF.withColumnRenamed(\"text_reviews_count\", \"reviews_count\")\n",
    "booksRenamedDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new column based on another\n",
    "\n",
    "* Typically how we engineer our columns is to create another column based on a previous one using `withColumn`\n",
    "\n",
    "In this example, we are bringing in the `booksDF` and we notice the `# num_pages` is using a `StringType`, so let's use a `cast` and create a new column with a better column name `num_pages` and ensure it is an `IntegerType`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bookID: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- # num_pages: string (nullable = true)\n",
      " |-- ratings_count: integer (nullable = true)\n",
      " |-- reviews_count: integer (nullable = true)\n",
      " |-- num_pages: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.IntegerType\n",
       "convertedDF: org.apache.spark.sql.DataFrame = [bookID: int, title: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.IntegerType\n",
    "val convertedDF = booksRenamedDF.withColumn(\"num_pages\", col(\"# num_pages\").cast(IntegerType))\n",
    "convertedDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the columns\n",
    "\n",
    "* We can drop the columns using `drop`\n",
    "* Since we have a table to with two columns that represent pages, we can drop the one we don't want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bookID: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- ratings_count: integer (nullable = true)\n",
      " |-- reviews_count: integer (nullable = true)\n",
      " |-- num_pages: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "finalDF: org.apache.spark.sql.DataFrame = [bookID: int, title: string ... 8 more fields]\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val finalDF = convertedDF.drop(\"# num_pages\")\n",
    "finalDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------+----------+-------------+-------------+-------------+------------------+---------+\n",
      "|bookID|               title|             authors|average_rating|      isbn|       isbn13|language_code|ratings_count|text_reviews_count|num_pages|\n",
      "+------+--------------------+--------------------+--------------+----------+-------------+-------------+-------------+------------------+---------+\n",
      "|     1|Harry Potter and ...|J.K. Rowling-Mary...|          4.56|0439785960|9780439785969|          eng|      1944099|             26249|      652|\n",
      "|     2|Harry Potter and ...|J.K. Rowling-Mary...|          4.49|0439358078|9780439358071|          eng|      1996446|             27613|      870|\n",
      "|     3|Harry Potter and ...|J.K. Rowling-Mary...|          4.47|0439554934|9780439554930|          eng|      5629932|             70390|      320|\n",
      "|     4|Harry Potter and ...|        J.K. Rowling|          4.41|0439554896|9780439554893|          eng|         6267|               272|      352|\n",
      "|     5|Harry Potter and ...|J.K. Rowling-Mary...|          4.55|043965548X|9780439655484|          eng|      2149872|             33964|      435|\n",
      "|     8|Harry Potter Boxe...|J.K. Rowling-Mary...|          4.78|0439682584|9780439682589|          eng|        38872|               154|     2690|\n",
      "|     9|Unauthorized Harr...|W. Frederick Zimm...|          3.69|0976540606|9780976540601|        en-US|           18|                 1|      152|\n",
      "|    10|Harry Potter Coll...|        J.K. Rowling|          4.73|0439827604|9780439827607|          eng|        27410|               820|     3342|\n",
      "|    12|The Ultimate Hitc...|       Douglas Adams|          4.38|0517226952|9780517226957|          eng|         3602|               258|      815|\n",
      "|    13|The Ultimate Hitc...|       Douglas Adams|          4.38|0345453743|9780345453747|          eng|       240189|              3954|      815|\n",
      "+------+--------------------+--------------------+--------------+----------+-------------+-------------+-------------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bookID: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- ratings_count: integer (nullable = true)\n",
      " |-- reviews_count: integer (nullable = true)\n",
      " |-- num_pages: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "final2: org.apache.spark.sql.DataFrame = [bookID: int, title: string ... 8 more fields]\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val final2 = booksDF.withColumnRenamed(\"text_reviews_count\", \"reviews_count\")\n",
    "                    .withColumn(\"num_pages\", col(\"# num_pages\").cast(IntegerType))\n",
    "                    .drop(\"# num_pages\")\n",
    "final2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------+----------+-------------+-------------+-------------+-------------+---------+\n",
      "|bookID|               title|             authors|average_rating|      isbn|       isbn13|language_code|ratings_count|reviews_count|num_pages|\n",
      "+------+--------------------+--------------------+--------------+----------+-------------+-------------+-------------+-------------+---------+\n",
      "|     1|Harry Potter and ...|J.K. Rowling-Mary...|          4.56|0439785960|9780439785969|          eng|      1944099|        26249|      652|\n",
      "|     2|Harry Potter and ...|J.K. Rowling-Mary...|          4.49|0439358078|9780439358071|          eng|      1996446|        27613|      870|\n",
      "|     3|Harry Potter and ...|J.K. Rowling-Mary...|          4.47|0439554934|9780439554930|          eng|      5629932|        70390|      320|\n",
      "|     4|Harry Potter and ...|        J.K. Rowling|          4.41|0439554896|9780439554893|          eng|         6267|          272|      352|\n",
      "|     5|Harry Potter and ...|J.K. Rowling-Mary...|          4.55|043965548X|9780439655484|          eng|      2149872|        33964|      435|\n",
      "|     8|Harry Potter Boxe...|J.K. Rowling-Mary...|          4.78|0439682584|9780439682589|          eng|        38872|          154|     2690|\n",
      "|     9|Unauthorized Harr...|W. Frederick Zimm...|          3.69|0976540606|9780976540601|        en-US|           18|            1|      152|\n",
      "|    10|Harry Potter Coll...|        J.K. Rowling|          4.73|0439827604|9780439827607|          eng|        27410|          820|     3342|\n",
      "|    12|The Ultimate Hitc...|       Douglas Adams|          4.38|0517226952|9780517226957|          eng|         3602|          258|      815|\n",
      "|    13|The Ultimate Hitc...|       Douglas Adams|          4.38|0345453743|9780345453747|          eng|       240189|         3954|      815|\n",
      "+------+--------------------+--------------------+--------------+----------+-------------+-------------+-------------+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Column Manipulation\n",
    "\n",
    "**Step 1:** Using the Schema provided for us by the inferencer already provided for you.\n",
    "\n",
    "**Step 2:** Print the Schema\n",
    "\n",
    "**Step 3:** Rename `_c0` to something better like `id`\n",
    "\n",
    "**Step 4:** Convert column `price` to Double Types\n",
    "\n",
    "**Step 5:** Convert column `points` to Integer Types\n",
    "\n",
    "**Step 4:** Convert columns `id` to Integer Type\n",
    "\n",
    "**Step 5:** Print the Schema\n",
    "\n",
    "**Step 6:** Show the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winesDF: org.apache.spark.sql.DataFrame = [_c0: string, country: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val winesDF = spark.read.format(\"csv\")\n",
    "                     .option(\"inferSchema\", \"true\")\n",
    "                     .option(\"header\", \"true\")\n",
    "                     .load(\"../data/winemag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- designation: string (nullable = true)\n",
      " |-- points: integer (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- region_1: string (nullable = true)\n",
      " |-- region_2: string (nullable = true)\n",
      " |-- taster_name: string (nullable = true)\n",
      " |-- taster_twitter_handle: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- variety: string (nullable = true)\n",
      " |-- winery: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.DoubleType\n",
       "cleanWinesDF: org.apache.spark.sql.DataFrame = [id: int, country: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.DoubleType\n",
    "val cleanWinesDF = winesDF\n",
    "                     .withColumn(\"price\", $\"price\".cast(DoubleType))\n",
    "                     .withColumnRenamed(\"_c0\", \"id\")\n",
    "                     .withColumn(\"id\", $\"id\".cast(IntegerType))\n",
    "                     .withColumn(\"points\", $\"points\".cast(IntegerType))\n",
    "cleanWinesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+--------------------+------+-----+-----------------+-------------------+-----------------+------------------+---------------------+--------------------+------------------+-------------------+\n",
      "| id| country|         description|         designation|points|price|         province|           region_1|         region_2|       taster_name|taster_twitter_handle|               title|           variety|             winery|\n",
      "+---+--------+--------------------+--------------------+------+-----+-----------------+-------------------+-----------------+------------------+---------------------+--------------------+------------------+-------------------+\n",
      "|  0|   Italy|Aromas include tr...|        Vulkà Bianco|    87| null|Sicily & Sardinia|               Etna|             null|     Kerin O’Keefe|         @kerinokeefe|Nicosia 2013 Vulk...|       White Blend|            Nicosia|\n",
      "|  1|Portugal|This is ripe and ...|            Avidagos|    87| 15.0|            Douro|               null|             null|        Roger Voss|           @vossroger|Quinta dos Avidag...|    Portuguese Red|Quinta dos Avidagos|\n",
      "|  2|      US|Tart and snappy, ...|                null|    87| 14.0|           Oregon|  Willamette Valley|Willamette Valley|      Paul Gregutt|          @paulgwine |Rainstorm 2013 Pi...|        Pinot Gris|          Rainstorm|\n",
      "|  3|      US|Pineapple rind, l...|Reserve Late Harvest|    87| 13.0|         Michigan|Lake Michigan Shore|             null|Alexander Peartree|                 null|St. Julian 2013 R...|          Riesling|         St. Julian|\n",
      "|  4|      US|Much like the reg...|Vintner's Reserve...|    87| 65.0|           Oregon|  Willamette Valley|Willamette Valley|      Paul Gregutt|          @paulgwine |Sweet Cheeks 2012...|        Pinot Noir|       Sweet Cheeks|\n",
      "|  5|   Spain|Blackberry and ra...|        Ars In Vitro|    87| 15.0|   Northern Spain|            Navarra|             null| Michael Schachner|          @wineschach|Tandem 2011 Ars I...|Tempranillo-Merlot|             Tandem|\n",
      "|  6|   Italy|Here's a bright, ...|             Belsito|    87| 16.0|Sicily & Sardinia|           Vittoria|             null|     Kerin O’Keefe|         @kerinokeefe|Terre di Giurfo 2...|          Frappato|    Terre di Giurfo|\n",
      "|  7|  France|This dry and rest...|                null|    87| 24.0|           Alsace|             Alsace|             null|        Roger Voss|           @vossroger|Trimbach 2012 Gew...|    Gewürztraminer|           Trimbach|\n",
      "|  8| Germany|Savory dried thym...|               Shine|    87| 12.0|      Rheinhessen|               null|             null|Anna Lee C. Iijima|                 null|Heinz Eifel 2013 ...|    Gewürztraminer|        Heinz Eifel|\n",
      "|  9|  France|This has great de...|         Les Natures|    87| 27.0|           Alsace|             Alsace|             null|        Roger Voss|           @vossroger|Jean-Baptiste Ada...|        Pinot Gris| Jean-Baptiste Adam|\n",
      "+---+--------+--------------------+--------------------+------+-----+-----------------+-------------------+-----------------+------------------+---------------------+--------------------+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanWinesDF.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
